{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4be45ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0582851",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HousingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "694dc3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a81878c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce6d8365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.611874</td>\n",
       "      <td>11.211934</td>\n",
       "      <td>11.083992</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.518519</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.715432</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.720192</td>\n",
       "      <td>23.388876</td>\n",
       "      <td>6.835896</td>\n",
       "      <td>0.255340</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>27.999513</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.155871</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.175000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.253715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>76.800000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.560263</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>93.975000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  486.000000  486.000000  486.000000  486.000000  506.000000  506.000000   \n",
       "mean     3.611874   11.211934   11.083992    0.069959    0.554695    6.284634   \n",
       "std      8.720192   23.388876    6.835896    0.255340    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081900    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.253715    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.560263   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  486.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.518519    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     27.999513    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.175000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     76.800000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     93.975000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  486.000000  506.000000  \n",
       "mean    12.715432   22.532806  \n",
       "std      7.155871    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      7.125000   17.025000  \n",
       "50%     11.430000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "779b362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    df[i].fillna(df[i].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe7018c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a91d7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('MEDV', axis = 1)\n",
    "Y = df['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c659e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f92c0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 128)               1792      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,161\n",
      "Trainable params: 12,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128,activation='relu',input_shape=X_train[0].shape))\n",
    "model.add(Dense(64, activation= 'relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1fd8db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa0a56d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "360/360 [==============================] - 0s 630us/step - loss: 130.2537 - mae: 7.8571 - val_loss: 67.5277 - val_mae: 5.5523\n",
      "Epoch 2/100\n",
      "360/360 [==============================] - 0s 478us/step - loss: 20.3076 - mae: 3.2226 - val_loss: 48.5637 - val_mae: 4.2068\n",
      "Epoch 3/100\n",
      "360/360 [==============================] - 0s 467us/step - loss: 15.4608 - mae: 2.8980 - val_loss: 40.8380 - val_mae: 4.0225\n",
      "Epoch 4/100\n",
      "360/360 [==============================] - 0s 482us/step - loss: 14.4934 - mae: 2.8101 - val_loss: 25.3417 - val_mae: 3.5307\n",
      "Epoch 5/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 13.7622 - mae: 2.6838 - val_loss: 36.3833 - val_mae: 3.9504\n",
      "Epoch 6/100\n",
      "360/360 [==============================] - 0s 467us/step - loss: 12.5302 - mae: 2.6465 - val_loss: 40.7076 - val_mae: 3.5550\n",
      "Epoch 7/100\n",
      "360/360 [==============================] - 0s 467us/step - loss: 11.1915 - mae: 2.5094 - val_loss: 40.4747 - val_mae: 3.8946\n",
      "Epoch 8/100\n",
      "360/360 [==============================] - 0s 459us/step - loss: 10.6206 - mae: 2.4396 - val_loss: 42.6366 - val_mae: 4.2001\n",
      "Epoch 9/100\n",
      "360/360 [==============================] - 0s 475us/step - loss: 9.9935 - mae: 2.4377 - val_loss: 29.3212 - val_mae: 3.4724\n",
      "Epoch 10/100\n",
      "360/360 [==============================] - 0s 466us/step - loss: 9.4013 - mae: 2.3207 - val_loss: 19.1067 - val_mae: 2.8610\n",
      "Epoch 11/100\n",
      "360/360 [==============================] - 0s 474us/step - loss: 9.1864 - mae: 2.2298 - val_loss: 23.5040 - val_mae: 3.2868\n",
      "Epoch 12/100\n",
      "360/360 [==============================] - 0s 470us/step - loss: 8.6748 - mae: 2.2108 - val_loss: 36.5410 - val_mae: 3.9989\n",
      "Epoch 13/100\n",
      "360/360 [==============================] - 0s 456us/step - loss: 9.2074 - mae: 2.2861 - val_loss: 25.4408 - val_mae: 3.2629\n",
      "Epoch 14/100\n",
      "360/360 [==============================] - 0s 474us/step - loss: 7.8314 - mae: 2.1455 - val_loss: 41.7254 - val_mae: 3.7813\n",
      "Epoch 15/100\n",
      "360/360 [==============================] - 0s 475us/step - loss: 9.3634 - mae: 2.3414 - val_loss: 19.3639 - val_mae: 2.8714\n",
      "Epoch 16/100\n",
      "360/360 [==============================] - 0s 467us/step - loss: 7.4820 - mae: 2.0672 - val_loss: 20.5927 - val_mae: 3.1480\n",
      "Epoch 17/100\n",
      "360/360 [==============================] - 0s 476us/step - loss: 7.1436 - mae: 2.0574 - val_loss: 24.6009 - val_mae: 3.5207\n",
      "Epoch 18/100\n",
      "360/360 [==============================] - 0s 485us/step - loss: 8.0182 - mae: 2.1646 - val_loss: 24.5688 - val_mae: 3.4807\n",
      "Epoch 19/100\n",
      "360/360 [==============================] - 0s 484us/step - loss: 6.9276 - mae: 1.9958 - val_loss: 23.9663 - val_mae: 3.3518\n",
      "Epoch 20/100\n",
      "360/360 [==============================] - 0s 483us/step - loss: 6.8174 - mae: 1.9925 - val_loss: 25.9098 - val_mae: 3.2083\n",
      "Epoch 21/100\n",
      "360/360 [==============================] - 0s 488us/step - loss: 6.6734 - mae: 2.0085 - val_loss: 24.1861 - val_mae: 3.3164\n",
      "Epoch 22/100\n",
      "360/360 [==============================] - 0s 475us/step - loss: 6.3158 - mae: 1.9058 - val_loss: 18.8915 - val_mae: 2.8825\n",
      "Epoch 23/100\n",
      "360/360 [==============================] - 0s 477us/step - loss: 5.7696 - mae: 1.7800 - val_loss: 28.2433 - val_mae: 3.4518\n",
      "Epoch 24/100\n",
      "360/360 [==============================] - 0s 477us/step - loss: 6.2475 - mae: 1.9270 - val_loss: 21.4365 - val_mae: 3.0867\n",
      "Epoch 25/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 5.6153 - mae: 1.8226 - val_loss: 25.4503 - val_mae: 3.3698\n",
      "Epoch 26/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 5.0865 - mae: 1.7898 - val_loss: 14.2095 - val_mae: 2.5008\n",
      "Epoch 27/100\n",
      "360/360 [==============================] - 0s 475us/step - loss: 7.1394 - mae: 2.0251 - val_loss: 24.0852 - val_mae: 3.3223\n",
      "Epoch 28/100\n",
      "360/360 [==============================] - 0s 485us/step - loss: 5.2645 - mae: 1.7634 - val_loss: 15.3678 - val_mae: 2.8652\n",
      "Epoch 29/100\n",
      "360/360 [==============================] - 0s 481us/step - loss: 5.4438 - mae: 1.7672 - val_loss: 25.6948 - val_mae: 3.7458\n",
      "Epoch 30/100\n",
      "360/360 [==============================] - 0s 472us/step - loss: 5.1619 - mae: 1.7125 - val_loss: 18.9928 - val_mae: 3.1848\n",
      "Epoch 31/100\n",
      "360/360 [==============================] - 0s 471us/step - loss: 5.2474 - mae: 1.7550 - val_loss: 24.1327 - val_mae: 3.3040\n",
      "Epoch 32/100\n",
      "360/360 [==============================] - 0s 471us/step - loss: 5.5519 - mae: 1.7924 - val_loss: 18.5962 - val_mae: 3.1875\n",
      "Epoch 33/100\n",
      "360/360 [==============================] - 0s 477us/step - loss: 5.5203 - mae: 1.8393 - val_loss: 22.2093 - val_mae: 3.0185\n",
      "Epoch 34/100\n",
      "360/360 [==============================] - 0s 481us/step - loss: 4.8599 - mae: 1.6626 - val_loss: 22.3468 - val_mae: 3.3442\n",
      "Epoch 35/100\n",
      "360/360 [==============================] - 0s 470us/step - loss: 4.5453 - mae: 1.6112 - val_loss: 26.5603 - val_mae: 3.4885\n",
      "Epoch 36/100\n",
      "360/360 [==============================] - 0s 472us/step - loss: 4.7607 - mae: 1.7032 - val_loss: 35.1781 - val_mae: 3.8269\n",
      "Epoch 37/100\n",
      "360/360 [==============================] - 0s 477us/step - loss: 4.5934 - mae: 1.6064 - val_loss: 16.4886 - val_mae: 2.6816\n",
      "Epoch 38/100\n",
      "360/360 [==============================] - 0s 471us/step - loss: 4.6867 - mae: 1.6267 - val_loss: 15.2333 - val_mae: 2.7310\n",
      "Epoch 39/100\n",
      "360/360 [==============================] - 0s 472us/step - loss: 4.6939 - mae: 1.6222 - val_loss: 23.6089 - val_mae: 3.1630\n",
      "Epoch 40/100\n",
      "360/360 [==============================] - 0s 475us/step - loss: 4.6454 - mae: 1.6211 - val_loss: 26.6999 - val_mae: 3.2201\n",
      "Epoch 41/100\n",
      "360/360 [==============================] - 0s 481us/step - loss: 4.6620 - mae: 1.6517 - val_loss: 18.8953 - val_mae: 2.9227\n",
      "Epoch 42/100\n",
      "360/360 [==============================] - 0s 479us/step - loss: 4.2147 - mae: 1.5717 - val_loss: 13.9862 - val_mae: 2.5590\n",
      "Epoch 43/100\n",
      "360/360 [==============================] - 0s 471us/step - loss: 4.1266 - mae: 1.5301 - val_loss: 23.7410 - val_mae: 3.4870\n",
      "Epoch 44/100\n",
      "360/360 [==============================] - 0s 480us/step - loss: 4.5284 - mae: 1.6048 - val_loss: 27.4990 - val_mae: 3.6641\n",
      "Epoch 45/100\n",
      "360/360 [==============================] - 0s 484us/step - loss: 4.3593 - mae: 1.5948 - val_loss: 26.8758 - val_mae: 3.4037\n",
      "Epoch 46/100\n",
      "360/360 [==============================] - 0s 493us/step - loss: 3.9400 - mae: 1.4886 - val_loss: 24.6386 - val_mae: 3.2568\n",
      "Epoch 47/100\n",
      "360/360 [==============================] - 0s 479us/step - loss: 4.1526 - mae: 1.5833 - val_loss: 27.5753 - val_mae: 3.1511\n",
      "Epoch 48/100\n",
      "360/360 [==============================] - 0s 479us/step - loss: 3.8073 - mae: 1.4946 - val_loss: 19.7329 - val_mae: 2.9849\n",
      "Epoch 49/100\n",
      "360/360 [==============================] - 0s 484us/step - loss: 4.2814 - mae: 1.5886 - val_loss: 18.7420 - val_mae: 2.9316\n",
      "Epoch 50/100\n",
      "360/360 [==============================] - 0s 478us/step - loss: 3.8458 - mae: 1.4965 - val_loss: 10.3924 - val_mae: 2.4678\n",
      "Epoch 51/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 3.7685 - mae: 1.4733 - val_loss: 17.1133 - val_mae: 2.9054\n",
      "Epoch 52/100\n",
      "360/360 [==============================] - 0s 479us/step - loss: 3.3446 - mae: 1.3670 - val_loss: 25.2059 - val_mae: 3.5622\n",
      "Epoch 53/100\n",
      "360/360 [==============================] - 0s 478us/step - loss: 3.1493 - mae: 1.3507 - val_loss: 21.9495 - val_mae: 3.5357\n",
      "Epoch 54/100\n",
      "360/360 [==============================] - 0s 482us/step - loss: 3.7794 - mae: 1.4363 - val_loss: 15.9799 - val_mae: 2.8631\n",
      "Epoch 55/100\n",
      "360/360 [==============================] - 0s 482us/step - loss: 3.8111 - mae: 1.4400 - val_loss: 21.9367 - val_mae: 3.0669\n",
      "Epoch 56/100\n",
      "360/360 [==============================] - 0s 491us/step - loss: 3.9000 - mae: 1.4927 - val_loss: 19.1281 - val_mae: 3.0401\n",
      "Epoch 57/100\n",
      "360/360 [==============================] - 0s 488us/step - loss: 3.3726 - mae: 1.3980 - val_loss: 22.3120 - val_mae: 3.1756\n",
      "Epoch 58/100\n",
      "360/360 [==============================] - 0s 476us/step - loss: 4.1081 - mae: 1.4509 - val_loss: 22.3208 - val_mae: 3.1516\n",
      "Epoch 59/100\n",
      "360/360 [==============================] - 0s 475us/step - loss: 4.1747 - mae: 1.5073 - val_loss: 17.1469 - val_mae: 2.9287\n",
      "Epoch 60/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 3.5140 - mae: 1.4102 - val_loss: 27.3893 - val_mae: 3.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 3.3412 - mae: 1.3875 - val_loss: 24.1864 - val_mae: 3.1150\n",
      "Epoch 62/100\n",
      "360/360 [==============================] - 0s 476us/step - loss: 3.0416 - mae: 1.3002 - val_loss: 30.1721 - val_mae: 3.1165\n",
      "Epoch 63/100\n",
      "360/360 [==============================] - 0s 479us/step - loss: 3.1896 - mae: 1.3292 - val_loss: 26.7327 - val_mae: 3.4047\n",
      "Epoch 64/100\n",
      "360/360 [==============================] - 0s 466us/step - loss: 3.0172 - mae: 1.2767 - val_loss: 25.2819 - val_mae: 3.1979\n",
      "Epoch 65/100\n",
      "360/360 [==============================] - 0s 474us/step - loss: 3.0539 - mae: 1.2877 - val_loss: 22.5534 - val_mae: 3.1544\n",
      "Epoch 66/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 2.8844 - mae: 1.3120 - val_loss: 23.6969 - val_mae: 3.3996\n",
      "Epoch 67/100\n",
      "360/360 [==============================] - 0s 483us/step - loss: 3.5632 - mae: 1.4768 - val_loss: 23.2935 - val_mae: 3.2065\n",
      "Epoch 68/100\n",
      "360/360 [==============================] - 0s 482us/step - loss: 3.8546 - mae: 1.4090 - val_loss: 28.1761 - val_mae: 3.1269\n",
      "Epoch 69/100\n",
      "360/360 [==============================] - 0s 480us/step - loss: 3.2919 - mae: 1.3184 - val_loss: 22.5575 - val_mae: 2.9747\n",
      "Epoch 70/100\n",
      "360/360 [==============================] - 0s 475us/step - loss: 3.2221 - mae: 1.3064 - val_loss: 18.1237 - val_mae: 2.7859\n",
      "Epoch 71/100\n",
      "360/360 [==============================] - 0s 476us/step - loss: 3.3913 - mae: 1.3248 - val_loss: 20.4958 - val_mae: 2.9310\n",
      "Epoch 72/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 2.5866 - mae: 1.2291 - val_loss: 18.2905 - val_mae: 3.0397\n",
      "Epoch 73/100\n",
      "360/360 [==============================] - 0s 483us/step - loss: 2.5854 - mae: 1.2049 - val_loss: 16.5664 - val_mae: 2.5824\n",
      "Epoch 74/100\n",
      "360/360 [==============================] - 0s 477us/step - loss: 2.4898 - mae: 1.1910 - val_loss: 24.7201 - val_mae: 3.3238\n",
      "Epoch 75/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 2.5393 - mae: 1.2001 - val_loss: 23.7108 - val_mae: 3.1485\n",
      "Epoch 76/100\n",
      "360/360 [==============================] - 0s 476us/step - loss: 3.5581 - mae: 1.3555 - val_loss: 20.8725 - val_mae: 2.8656\n",
      "Epoch 77/100\n",
      "360/360 [==============================] - 0s 474us/step - loss: 2.9268 - mae: 1.2756 - val_loss: 16.9294 - val_mae: 2.7790\n",
      "Epoch 78/100\n",
      "360/360 [==============================] - 0s 476us/step - loss: 2.9517 - mae: 1.2874 - val_loss: 22.2106 - val_mae: 3.0683\n",
      "Epoch 79/100\n",
      "360/360 [==============================] - 0s 511us/step - loss: 2.7700 - mae: 1.2207 - val_loss: 23.3632 - val_mae: 3.1744\n",
      "Epoch 80/100\n",
      "360/360 [==============================] - 0s 482us/step - loss: 2.7812 - mae: 1.2275 - val_loss: 21.3085 - val_mae: 2.9718\n",
      "Epoch 81/100\n",
      "360/360 [==============================] - 0s 479us/step - loss: 2.7549 - mae: 1.2170 - val_loss: 30.8311 - val_mae: 3.4541\n",
      "Epoch 82/100\n",
      "360/360 [==============================] - 0s 474us/step - loss: 2.9735 - mae: 1.2635 - val_loss: 36.9548 - val_mae: 3.8489\n",
      "Epoch 83/100\n",
      "360/360 [==============================] - 0s 478us/step - loss: 3.7541 - mae: 1.4068 - val_loss: 22.8656 - val_mae: 3.1155\n",
      "Epoch 84/100\n",
      "360/360 [==============================] - 0s 478us/step - loss: 2.3840 - mae: 1.1437 - val_loss: 17.9543 - val_mae: 2.9511\n",
      "Epoch 85/100\n",
      "360/360 [==============================] - 0s 473us/step - loss: 2.2391 - mae: 1.0878 - val_loss: 24.1884 - val_mae: 3.1617\n",
      "Epoch 86/100\n",
      "360/360 [==============================] - 0s 487us/step - loss: 2.4804 - mae: 1.1782 - val_loss: 24.6099 - val_mae: 3.1884\n",
      "Epoch 87/100\n",
      "360/360 [==============================] - 0s 497us/step - loss: 2.8147 - mae: 1.2804 - val_loss: 27.2212 - val_mae: 3.1623\n",
      "Epoch 88/100\n",
      "360/360 [==============================] - 0s 474us/step - loss: 2.7334 - mae: 1.2403 - val_loss: 30.3431 - val_mae: 3.4051\n",
      "Epoch 89/100\n",
      "360/360 [==============================] - 0s 478us/step - loss: 2.0357 - mae: 1.1005 - val_loss: 18.6947 - val_mae: 2.8065\n",
      "Epoch 90/100\n",
      "360/360 [==============================] - 0s 478us/step - loss: 2.4032 - mae: 1.1423 - val_loss: 22.1112 - val_mae: 3.1668\n",
      "Epoch 91/100\n",
      "360/360 [==============================] - 0s 481us/step - loss: 1.6111 - mae: 0.9466 - val_loss: 22.5454 - val_mae: 3.0709\n",
      "Epoch 92/100\n",
      "360/360 [==============================] - 0s 480us/step - loss: 2.2839 - mae: 1.1426 - val_loss: 25.0781 - val_mae: 2.9767\n",
      "Epoch 93/100\n",
      "360/360 [==============================] - 0s 479us/step - loss: 2.0065 - mae: 1.0737 - val_loss: 27.8737 - val_mae: 3.2011\n",
      "Epoch 94/100\n",
      "360/360 [==============================] - 0s 482us/step - loss: 2.9002 - mae: 1.2786 - val_loss: 25.2552 - val_mae: 3.0455\n",
      "Epoch 95/100\n",
      "360/360 [==============================] - 0s 488us/step - loss: 2.1305 - mae: 1.1095 - val_loss: 22.9311 - val_mae: 3.0988\n",
      "Epoch 96/100\n",
      "360/360 [==============================] - 0s 502us/step - loss: 2.1144 - mae: 1.1065 - val_loss: 15.4676 - val_mae: 2.6430\n",
      "Epoch 97/100\n",
      "360/360 [==============================] - 0s 486us/step - loss: 2.1625 - mae: 1.0845 - val_loss: 19.3986 - val_mae: 3.1193\n",
      "Epoch 98/100\n",
      "360/360 [==============================] - 0s 495us/step - loss: 1.8812 - mae: 1.0326 - val_loss: 26.7058 - val_mae: 3.2394\n",
      "Epoch 99/100\n",
      "360/360 [==============================] - 0s 483us/step - loss: 1.9557 - mae: 1.0297 - val_loss: 23.8320 - val_mae: 3.1805\n",
      "Epoch 100/100\n",
      "360/360 [==============================] - 0s 485us/step - loss: 2.1124 - mae: 1.1070 - val_loss: 17.8601 - val_mae: 2.7197\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs = 100, batch_size = 1,verbose=1, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee8e8af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: [[26.75484  ]\n",
      " [34.66964  ]\n",
      " [14.288132 ]\n",
      " [23.685146 ]\n",
      " [16.70251  ]\n",
      " [17.750969 ]\n",
      " [18.858839 ]\n",
      " [13.665091 ]\n",
      " [23.75968  ]\n",
      " [17.653091 ]\n",
      " [21.839775 ]\n",
      " [22.022694 ]\n",
      " [ 9.553204 ]\n",
      " [18.069115 ]\n",
      " [16.699253 ]\n",
      " [21.873629 ]\n",
      " [19.797573 ]\n",
      " [10.410982 ]\n",
      " [48.840958 ]\n",
      " [11.885246 ]\n",
      " [25.820284 ]\n",
      " [26.848036 ]\n",
      " [13.1968975]\n",
      " [23.419281 ]\n",
      " [18.514648 ]\n",
      " [18.637493 ]\n",
      " [18.855045 ]\n",
      " [13.606331 ]\n",
      " [20.13978  ]\n",
      " [17.087452 ]\n",
      " [19.841892 ]\n",
      " [23.0061   ]\n",
      " [17.35578  ]\n",
      " [18.486574 ]\n",
      " [16.239222 ]\n",
      " [15.152679 ]\n",
      " [29.930614 ]\n",
      " [18.360523 ]\n",
      " [21.769035 ]\n",
      " [23.367306 ]\n",
      " [13.422377 ]\n",
      " [30.01796  ]\n",
      " [54.21529  ]\n",
      " [18.336926 ]\n",
      " [22.132849 ]\n",
      " [10.424234 ]\n",
      " [14.436548 ]\n",
      " [25.03053  ]\n",
      " [19.93895  ]\n",
      " [23.707632 ]\n",
      " [23.14833  ]\n",
      " [35.271587 ]\n",
      " [15.131664 ]\n",
      " [26.041803 ]\n",
      " [45.895496 ]\n",
      " [22.227186 ]\n",
      " [12.288279 ]\n",
      " [34.212265 ]\n",
      " [23.08039  ]\n",
      " [14.605421 ]\n",
      " [28.670393 ]\n",
      " [38.848095 ]\n",
      " [28.90923  ]\n",
      " [16.444973 ]\n",
      " [25.438087 ]\n",
      " [20.147488 ]\n",
      " [14.021627 ]\n",
      " [24.578072 ]\n",
      " [30.516518 ]\n",
      " [14.374863 ]\n",
      " [20.900414 ]\n",
      " [26.222683 ]\n",
      " [10.852018 ]\n",
      " [22.49207  ]\n",
      " [19.70158  ]\n",
      " [ 7.7276545]\n",
      " [18.50397  ]\n",
      " [51.188747 ]\n",
      " [11.97583  ]\n",
      " [10.487396 ]\n",
      " [21.521988 ]\n",
      " [11.709133 ]\n",
      " [22.909187 ]\n",
      " [11.027241 ]\n",
      " [18.271214 ]\n",
      " [26.36973  ]\n",
      " [16.207413 ]\n",
      " [23.652428 ]\n",
      " [24.436813 ]\n",
      " [17.555592 ]\n",
      " [21.404835 ]\n",
      " [ 9.323654 ]\n",
      " [17.619877 ]\n",
      " [15.873705 ]\n",
      " [21.65569  ]\n",
      " [18.232658 ]\n",
      " [32.26021  ]\n",
      " [10.201546 ]\n",
      " [12.756416 ]\n",
      " [12.135172 ]\n",
      " [21.021328 ]\n",
      " [20.064405 ]\n",
      " [10.896294 ]\n",
      " [17.835983 ]\n",
      " [20.14608  ]\n",
      " [ 8.814041 ]\n",
      " [16.310608 ]\n",
      " [24.36784  ]\n",
      " [20.345655 ]\n",
      " [25.753325 ]\n",
      " [ 9.710163 ]\n",
      " [16.208422 ]\n",
      " [22.017256 ]\n",
      " [26.167555 ]\n",
      " [30.208326 ]\n",
      " [14.255451 ]\n",
      " [40.339127 ]\n",
      " [14.271963 ]\n",
      " [17.335503 ]\n",
      " [24.808178 ]\n",
      " [16.357368 ]\n",
      " [26.770401 ]\n",
      " [ 8.342649 ]\n",
      " [16.080008 ]\n",
      " [23.56284  ]\n",
      " [19.791925 ]\n",
      " [27.867159 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Output:\",model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "80dd99b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 927us/step - loss: 11.2715 - mae: 2.3217\n",
      "Mean squared error on test data:  11.271480560302734\n",
      "Mean absolute error on test data:  2.3217055797576904\n"
     ]
    }
   ],
   "source": [
    "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
    "print('Mean squared error on test data: ', mse_nn)\n",
    "print('Mean absolute error on test data: ', mae_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4ef735",
   "metadata": {},
   "source": [
    "**PRACTICE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d23cfb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35144d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HousingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0fe41a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "db827121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aba0333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    df[i].fillna(df[i].mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "09138fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "43b428fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop('MEDV', axis =1)\n",
    "Y= df['MEDV']\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y, test_size= 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "57d02025",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9a9e8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = X_train[0].shape, activation = 'relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(optimizer = 'adam', loss='mse',metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a86787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "336/336 [==============================] - 0s 612us/step - loss: 160.1229 - mae: 8.7874 - val_loss: 58.6334 - val_mae: 5.0872\n",
      "Epoch 2/100\n",
      "336/336 [==============================] - 0s 467us/step - loss: 23.1076 - mae: 3.5508 - val_loss: 52.2679 - val_mae: 4.6076\n",
      "Epoch 3/100\n",
      "336/336 [==============================] - 0s 469us/step - loss: 18.2400 - mae: 3.1268 - val_loss: 51.0570 - val_mae: 4.8939\n",
      "Epoch 4/100\n",
      "336/336 [==============================] - 0s 469us/step - loss: 15.7591 - mae: 2.9095 - val_loss: 47.0594 - val_mae: 4.5032\n",
      "Epoch 5/100\n",
      "336/336 [==============================] - 0s 470us/step - loss: 14.4819 - mae: 2.7960 - val_loss: 49.7373 - val_mae: 4.5511\n",
      "Epoch 6/100\n",
      "336/336 [==============================] - 0s 464us/step - loss: 13.0474 - mae: 2.6846 - val_loss: 35.9456 - val_mae: 3.8751\n",
      "Epoch 7/100\n",
      "336/336 [==============================] - 0s 468us/step - loss: 12.3981 - mae: 2.6455 - val_loss: 22.1314 - val_mae: 2.8745\n",
      "Epoch 8/100\n",
      "336/336 [==============================] - 0s 467us/step - loss: 12.5576 - mae: 2.6742 - val_loss: 33.9448 - val_mae: 3.6419\n",
      "Epoch 9/100\n",
      "336/336 [==============================] - 0s 467us/step - loss: 11.2702 - mae: 2.5043 - val_loss: 38.5878 - val_mae: 3.8362\n",
      "Epoch 10/100\n",
      "336/336 [==============================] - 0s 468us/step - loss: 12.1138 - mae: 2.5837 - val_loss: 33.4272 - val_mae: 4.1264\n",
      "Epoch 11/100\n",
      "336/336 [==============================] - 0s 473us/step - loss: 10.9291 - mae: 2.5360 - val_loss: 35.3552 - val_mae: 4.1343\n",
      "Epoch 12/100\n",
      "336/336 [==============================] - 0s 470us/step - loss: 9.5757 - mae: 2.3432 - val_loss: 32.6064 - val_mae: 3.8717\n",
      "Epoch 13/100\n",
      "336/336 [==============================] - 0s 465us/step - loss: 9.3228 - mae: 2.2997 - val_loss: 27.9091 - val_mae: 3.7487\n",
      "Epoch 14/100\n",
      "336/336 [==============================] - 0s 472us/step - loss: 9.5536 - mae: 2.3792 - val_loss: 34.1681 - val_mae: 3.4557\n",
      "Epoch 15/100\n",
      "336/336 [==============================] - 0s 472us/step - loss: 8.4699 - mae: 2.2143 - val_loss: 32.7384 - val_mae: 3.8148\n",
      "Epoch 16/100\n",
      "336/336 [==============================] - 0s 476us/step - loss: 8.1380 - mae: 2.1774 - val_loss: 21.9823 - val_mae: 3.1504\n",
      "Epoch 17/100\n",
      "336/336 [==============================] - 0s 473us/step - loss: 7.8514 - mae: 2.1347 - val_loss: 29.3834 - val_mae: 3.7226\n",
      "Epoch 18/100\n",
      "336/336 [==============================] - 0s 477us/step - loss: 7.8007 - mae: 2.1189 - val_loss: 22.3167 - val_mae: 3.2312\n",
      "Epoch 19/100\n",
      "336/336 [==============================] - 0s 475us/step - loss: 7.8082 - mae: 2.1172 - val_loss: 25.1992 - val_mae: 3.2645\n",
      "Epoch 20/100\n",
      "336/336 [==============================] - 0s 487us/step - loss: 7.5842 - mae: 2.1433 - val_loss: 20.4550 - val_mae: 2.7840\n",
      "Epoch 21/100\n",
      "336/336 [==============================] - 0s 487us/step - loss: 6.4728 - mae: 1.9586 - val_loss: 26.2056 - val_mae: 3.6204\n",
      "Epoch 22/100\n",
      "336/336 [==============================] - 0s 482us/step - loss: 6.7415 - mae: 1.9760 - val_loss: 29.2191 - val_mae: 3.5163\n",
      "Epoch 23/100\n",
      "336/336 [==============================] - 0s 504us/step - loss: 6.7345 - mae: 1.9926 - val_loss: 28.4110 - val_mae: 3.6511\n",
      "Epoch 24/100\n",
      "336/336 [==============================] - 0s 478us/step - loss: 7.6443 - mae: 2.1259 - val_loss: 15.2902 - val_mae: 2.5902\n",
      "Epoch 25/100\n",
      "336/336 [==============================] - 0s 472us/step - loss: 5.7862 - mae: 1.8469 - val_loss: 17.0294 - val_mae: 2.9784\n",
      "Epoch 26/100\n",
      "336/336 [==============================] - 0s 467us/step - loss: 6.0631 - mae: 1.8275 - val_loss: 24.2991 - val_mae: 3.6701\n",
      "Epoch 27/100\n",
      "336/336 [==============================] - 0s 470us/step - loss: 6.0490 - mae: 1.8660 - val_loss: 25.1582 - val_mae: 3.6204\n",
      "Epoch 28/100\n",
      "336/336 [==============================] - 0s 469us/step - loss: 5.7310 - mae: 1.8587 - val_loss: 22.6386 - val_mae: 3.2020\n",
      "Epoch 29/100\n",
      "336/336 [==============================] - 0s 485us/step - loss: 5.2157 - mae: 1.7243 - val_loss: 17.6933 - val_mae: 3.0615\n",
      "Epoch 30/100\n",
      "336/336 [==============================] - 0s 477us/step - loss: 5.5533 - mae: 1.8132 - val_loss: 24.2604 - val_mae: 3.5273\n",
      "Epoch 31/100\n",
      "336/336 [==============================] - 0s 495us/step - loss: 4.8158 - mae: 1.7187 - val_loss: 23.7662 - val_mae: 3.0684\n",
      "Epoch 32/100\n",
      "336/336 [==============================] - 0s 488us/step - loss: 4.9750 - mae: 1.7631 - val_loss: 21.6347 - val_mae: 3.2985\n",
      "Epoch 33/100\n",
      "336/336 [==============================] - 0s 468us/step - loss: 4.7050 - mae: 1.6688 - val_loss: 24.8897 - val_mae: 3.4874\n",
      "Epoch 34/100\n",
      "336/336 [==============================] - 0s 483us/step - loss: 4.7914 - mae: 1.6524 - val_loss: 15.1930 - val_mae: 2.4545\n",
      "Epoch 35/100\n",
      "336/336 [==============================] - 0s 491us/step - loss: 5.3058 - mae: 1.7423 - val_loss: 13.4425 - val_mae: 2.5081\n",
      "Epoch 36/100\n",
      "336/336 [==============================] - 0s 472us/step - loss: 5.2303 - mae: 1.7641 - val_loss: 16.8620 - val_mae: 3.0032\n",
      "Epoch 37/100\n",
      "336/336 [==============================] - 0s 487us/step - loss: 4.4615 - mae: 1.5887 - val_loss: 14.6942 - val_mae: 2.7168\n",
      "Epoch 38/100\n",
      "336/336 [==============================] - 0s 488us/step - loss: 4.7270 - mae: 1.6490 - val_loss: 20.7348 - val_mae: 3.4991\n",
      "Epoch 39/100\n",
      "336/336 [==============================] - 0s 494us/step - loss: 4.4346 - mae: 1.6207 - val_loss: 17.9408 - val_mae: 2.8975\n",
      "Epoch 40/100\n",
      "336/336 [==============================] - 0s 505us/step - loss: 5.0978 - mae: 1.7558 - val_loss: 18.1760 - val_mae: 2.8329\n",
      "Epoch 41/100\n",
      "336/336 [==============================] - 0s 471us/step - loss: 4.3717 - mae: 1.5948 - val_loss: 19.9008 - val_mae: 2.9391\n",
      "Epoch 42/100\n",
      "336/336 [==============================] - 0s 488us/step - loss: 4.3119 - mae: 1.6415 - val_loss: 21.3731 - val_mae: 3.1857\n",
      "Epoch 43/100\n",
      "336/336 [==============================] - 0s 505us/step - loss: 4.2640 - mae: 1.5301 - val_loss: 22.1934 - val_mae: 2.9525\n",
      "Epoch 44/100\n",
      "336/336 [==============================] - 0s 484us/step - loss: 3.7701 - mae: 1.4975 - val_loss: 19.5341 - val_mae: 2.9908\n",
      "Epoch 45/100\n",
      "336/336 [==============================] - 0s 466us/step - loss: 3.9703 - mae: 1.5294 - val_loss: 19.8676 - val_mae: 3.2542\n",
      "Epoch 46/100\n",
      "336/336 [==============================] - 0s 490us/step - loss: 4.2710 - mae: 1.5493 - val_loss: 22.7653 - val_mae: 3.3446\n",
      "Epoch 47/100\n",
      "336/336 [==============================] - 0s 494us/step - loss: 3.7624 - mae: 1.4788 - val_loss: 20.2281 - val_mae: 2.9055\n",
      "Epoch 48/100\n",
      "336/336 [==============================] - 0s 471us/step - loss: 4.2126 - mae: 1.5504 - val_loss: 21.4844 - val_mae: 2.8577\n",
      "Epoch 49/100\n",
      "336/336 [==============================] - 0s 479us/step - loss: 3.7536 - mae: 1.4753 - val_loss: 21.7000 - val_mae: 3.1281\n",
      "Epoch 50/100\n",
      "336/336 [==============================] - 0s 490us/step - loss: 3.1978 - mae: 1.4021 - val_loss: 20.0659 - val_mae: 2.8756\n",
      "Epoch 51/100\n",
      "336/336 [==============================] - 0s 507us/step - loss: 3.2938 - mae: 1.4161 - val_loss: 18.8767 - val_mae: 2.5245\n",
      "Epoch 52/100\n",
      "336/336 [==============================] - 0s 509us/step - loss: 3.6466 - mae: 1.4602 - val_loss: 24.8757 - val_mae: 3.3034\n",
      "Epoch 53/100\n",
      "336/336 [==============================] - 0s 504us/step - loss: 3.8015 - mae: 1.4704 - val_loss: 17.6443 - val_mae: 2.9845\n",
      "Epoch 54/100\n",
      "336/336 [==============================] - 0s 514us/step - loss: 3.3909 - mae: 1.4013 - val_loss: 16.9194 - val_mae: 2.7590\n",
      "Epoch 55/100\n",
      "336/336 [==============================] - 0s 501us/step - loss: 3.5515 - mae: 1.4428 - val_loss: 26.0645 - val_mae: 3.4508\n",
      "Epoch 56/100\n",
      "336/336 [==============================] - 0s 483us/step - loss: 3.4003 - mae: 1.4092 - val_loss: 22.3630 - val_mae: 3.3816\n",
      "Epoch 57/100\n",
      "336/336 [==============================] - 0s 484us/step - loss: 3.2076 - mae: 1.3731 - val_loss: 22.9255 - val_mae: 3.1837\n",
      "Epoch 58/100\n",
      "336/336 [==============================] - 0s 473us/step - loss: 2.9687 - mae: 1.3124 - val_loss: 18.7037 - val_mae: 2.8412\n",
      "Epoch 59/100\n",
      "336/336 [==============================] - 0s 485us/step - loss: 3.1469 - mae: 1.3398 - val_loss: 20.4902 - val_mae: 3.0846\n",
      "Epoch 60/100\n",
      "336/336 [==============================] - 0s 519us/step - loss: 3.6831 - mae: 1.4368 - val_loss: 19.4989 - val_mae: 3.0211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "336/336 [==============================] - 0s 541us/step - loss: 3.6767 - mae: 1.4435 - val_loss: 20.1232 - val_mae: 2.7745\n",
      "Epoch 62/100\n",
      "336/336 [==============================] - 0s 503us/step - loss: 3.2869 - mae: 1.3696 - val_loss: 21.6827 - val_mae: 2.9133\n",
      "Epoch 63/100\n",
      "336/336 [==============================] - 0s 484us/step - loss: 3.6569 - mae: 1.4050 - val_loss: 16.8120 - val_mae: 2.7688\n",
      "Epoch 64/100\n",
      "336/336 [==============================] - 0s 476us/step - loss: 2.8097 - mae: 1.2415 - val_loss: 14.4436 - val_mae: 2.6120\n",
      "Epoch 65/100\n",
      "336/336 [==============================] - 0s 494us/step - loss: 2.7452 - mae: 1.2720 - val_loss: 21.8799 - val_mae: 3.1452\n",
      "Epoch 66/100\n",
      "336/336 [==============================] - 0s 508us/step - loss: 2.7234 - mae: 1.2673 - val_loss: 19.2593 - val_mae: 3.1116\n",
      "Epoch 67/100\n",
      "336/336 [==============================] - 0s 510us/step - loss: 2.6884 - mae: 1.2764 - val_loss: 18.7335 - val_mae: 2.6948\n",
      "Epoch 68/100\n",
      "336/336 [==============================] - 0s 498us/step - loss: 3.3914 - mae: 1.3597 - val_loss: 19.2398 - val_mae: 2.8823\n",
      "Epoch 69/100\n",
      "336/336 [==============================] - 0s 506us/step - loss: 3.0277 - mae: 1.3054 - val_loss: 22.0813 - val_mae: 3.0558\n",
      "Epoch 70/100\n",
      "336/336 [==============================] - 0s 491us/step - loss: 2.9047 - mae: 1.3193 - val_loss: 18.8551 - val_mae: 2.9276\n",
      "Epoch 71/100\n",
      "336/336 [==============================] - 0s 509us/step - loss: 2.9457 - mae: 1.2807 - val_loss: 19.6455 - val_mae: 3.1428\n",
      "Epoch 72/100\n",
      "336/336 [==============================] - 0s 500us/step - loss: 2.8879 - mae: 1.2937 - val_loss: 18.8767 - val_mae: 2.8726\n",
      "Epoch 73/100\n",
      "336/336 [==============================] - 0s 473us/step - loss: 2.9060 - mae: 1.2821 - val_loss: 20.1674 - val_mae: 2.9664\n",
      "Epoch 74/100\n",
      "336/336 [==============================] - 0s 470us/step - loss: 2.7457 - mae: 1.2727 - val_loss: 15.7258 - val_mae: 2.7051\n",
      "Epoch 75/100\n",
      "336/336 [==============================] - 0s 467us/step - loss: 2.6423 - mae: 1.2460 - val_loss: 17.0552 - val_mae: 2.5973\n",
      "Epoch 76/100\n",
      "336/336 [==============================] - 0s 477us/step - loss: 2.6527 - mae: 1.2850 - val_loss: 19.5242 - val_mae: 2.8261\n",
      "Epoch 77/100\n",
      "336/336 [==============================] - 0s 470us/step - loss: 2.9837 - mae: 1.3020 - val_loss: 24.5454 - val_mae: 3.0972\n",
      "Epoch 78/100\n",
      "336/336 [==============================] - 0s 472us/step - loss: 2.5878 - mae: 1.2397 - val_loss: 24.3862 - val_mae: 3.3782\n",
      "Epoch 79/100\n",
      "336/336 [==============================] - 0s 469us/step - loss: 2.8901 - mae: 1.3041 - val_loss: 17.6578 - val_mae: 2.5840\n",
      "Epoch 80/100\n",
      "336/336 [==============================] - 0s 480us/step - loss: 2.3968 - mae: 1.1851 - val_loss: 19.4485 - val_mae: 2.8353\n",
      "Epoch 81/100\n",
      "336/336 [==============================] - 0s 470us/step - loss: 2.7478 - mae: 1.2324 - val_loss: 17.5566 - val_mae: 2.8882\n",
      "Epoch 82/100\n",
      "336/336 [==============================] - 0s 483us/step - loss: 2.3371 - mae: 1.1501 - val_loss: 27.5278 - val_mae: 3.2143\n",
      "Epoch 83/100\n",
      "336/336 [==============================] - 0s 471us/step - loss: 2.8498 - mae: 1.2400 - val_loss: 18.0572 - val_mae: 2.9138\n",
      "Epoch 84/100\n",
      "336/336 [==============================] - 0s 477us/step - loss: 2.7797 - mae: 1.2207 - val_loss: 19.3885 - val_mae: 2.9460\n",
      "Epoch 85/100\n",
      "336/336 [==============================] - 0s 467us/step - loss: 2.3360 - mae: 1.1205 - val_loss: 25.2681 - val_mae: 3.3007\n",
      "Epoch 86/100\n",
      "336/336 [==============================] - 0s 472us/step - loss: 2.5577 - mae: 1.2193 - val_loss: 21.3916 - val_mae: 3.3671\n",
      "Epoch 87/100\n",
      "336/336 [==============================] - 0s 470us/step - loss: 2.5284 - mae: 1.2125 - val_loss: 19.7752 - val_mae: 3.0274\n",
      "Epoch 88/100\n",
      "336/336 [==============================] - 0s 470us/step - loss: 2.0131 - mae: 1.0723 - val_loss: 18.7173 - val_mae: 2.7878\n",
      "Epoch 89/100\n",
      "336/336 [==============================] - 0s 477us/step - loss: 2.5693 - mae: 1.1896 - val_loss: 15.4729 - val_mae: 2.5423\n",
      "Epoch 90/100\n",
      "336/336 [==============================] - 0s 478us/step - loss: 3.4857 - mae: 1.4226 - val_loss: 25.2114 - val_mae: 3.4261\n",
      "Epoch 91/100\n",
      "336/336 [==============================] - 0s 464us/step - loss: 2.2867 - mae: 1.1471 - val_loss: 16.8610 - val_mae: 3.0871\n",
      "Epoch 92/100\n",
      "336/336 [==============================] - 0s 469us/step - loss: 2.1003 - mae: 1.1140 - val_loss: 22.4155 - val_mae: 3.2726\n",
      "Epoch 93/100\n",
      "336/336 [==============================] - 0s 472us/step - loss: 1.7705 - mae: 1.0110 - val_loss: 21.4122 - val_mae: 2.9337\n",
      "Epoch 94/100\n",
      "336/336 [==============================] - 0s 466us/step - loss: 1.9636 - mae: 1.1201 - val_loss: 16.3400 - val_mae: 2.8550\n",
      "Epoch 95/100\n",
      "336/336 [==============================] - 0s 480us/step - loss: 2.4167 - mae: 1.1949 - val_loss: 23.2878 - val_mae: 3.4039\n",
      "Epoch 96/100\n",
      "336/336 [==============================] - 0s 504us/step - loss: 2.5574 - mae: 1.2116 - val_loss: 19.3709 - val_mae: 3.0365\n",
      "Epoch 97/100\n",
      "336/336 [==============================] - 0s 474us/step - loss: 2.3078 - mae: 1.1545 - val_loss: 16.7266 - val_mae: 2.8966\n",
      "Epoch 98/100\n",
      "336/336 [==============================] - 0s 468us/step - loss: 2.4286 - mae: 1.1700 - val_loss: 22.0113 - val_mae: 3.1530\n",
      "Epoch 99/100\n",
      "336/336 [==============================] - 0s 468us/step - loss: 2.1927 - mae: 1.1077 - val_loss: 22.1316 - val_mae: 3.1840\n",
      "Epoch 100/100\n",
      "336/336 [==============================] - 0s 469us/step - loss: 1.9975 - mae: 1.0805 - val_loss: 20.9115 - val_mae: 2.9113\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 100, batch_size=1,verbose = 1, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "69b871e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output\n",
      " [[27.97985  ]\n",
      " [35.99195  ]\n",
      " [14.077275 ]\n",
      " [22.714622 ]\n",
      " [16.783892 ]\n",
      " [21.651918 ]\n",
      " [17.50344  ]\n",
      " [14.436126 ]\n",
      " [23.764069 ]\n",
      " [19.964928 ]\n",
      " [24.360996 ]\n",
      " [22.817177 ]\n",
      " [ 5.253857 ]\n",
      " [21.585707 ]\n",
      " [19.276178 ]\n",
      " [19.689175 ]\n",
      " [21.01112  ]\n",
      " [11.280877 ]\n",
      " [48.476467 ]\n",
      " [11.029208 ]\n",
      " [28.297642 ]\n",
      " [27.056995 ]\n",
      " [14.4800825]\n",
      " [25.986816 ]\n",
      " [18.828396 ]\n",
      " [16.930256 ]\n",
      " [21.489574 ]\n",
      " [16.23763  ]\n",
      " [22.601414 ]\n",
      " [19.422417 ]\n",
      " [25.200592 ]\n",
      " [25.475727 ]\n",
      " [15.855134 ]\n",
      " [16.261715 ]\n",
      " [17.071709 ]\n",
      " [17.447994 ]\n",
      " [32.45348  ]\n",
      " [18.779213 ]\n",
      " [23.053642 ]\n",
      " [27.700949 ]\n",
      " [17.522985 ]\n",
      " [30.47297  ]\n",
      " [52.41197  ]\n",
      " [17.633366 ]\n",
      " [24.822765 ]\n",
      " [ 9.520295 ]\n",
      " [17.06124  ]\n",
      " [25.346626 ]\n",
      " [18.84454  ]\n",
      " [24.586279 ]\n",
      " [23.58794  ]\n",
      " [34.647686 ]\n",
      " [17.460794 ]\n",
      " [27.370426 ]\n",
      " [46.661663 ]\n",
      " [21.78833  ]\n",
      " [ 9.62168  ]\n",
      " [35.60027  ]\n",
      " [26.70792  ]\n",
      " [16.509882 ]\n",
      " [28.209454 ]\n",
      " [36.020626 ]\n",
      " [28.57784  ]\n",
      " [15.088542 ]\n",
      " [24.871235 ]\n",
      " [24.30714  ]\n",
      " [12.152222 ]\n",
      " [24.430908 ]\n",
      " [30.729048 ]\n",
      " [15.433445 ]\n",
      " [21.329897 ]\n",
      " [25.560114 ]\n",
      " [10.810374 ]\n",
      " [24.066074 ]\n",
      " [21.347544 ]\n",
      " [ 5.4463   ]\n",
      " [19.979387 ]\n",
      " [49.553974 ]\n",
      " [11.7306795]\n",
      " [ 9.114163 ]\n",
      " [21.070713 ]\n",
      " [12.215564 ]\n",
      " [19.545935 ]\n",
      " [12.375583 ]\n",
      " [21.508675 ]\n",
      " [28.851948 ]\n",
      " [14.280386 ]\n",
      " [25.59182  ]\n",
      " [24.242617 ]\n",
      " [18.220844 ]\n",
      " [24.375397 ]\n",
      " [ 9.769985 ]\n",
      " [18.384325 ]\n",
      " [16.804262 ]\n",
      " [25.937426 ]\n",
      " [18.624804 ]\n",
      " [28.143257 ]\n",
      " [12.705334 ]\n",
      " [15.060466 ]\n",
      " [15.28091  ]\n",
      " [22.666603 ]\n",
      " [22.4903   ]\n",
      " [12.11532  ]\n",
      " [19.359802 ]\n",
      " [19.512962 ]\n",
      " [11.044517 ]\n",
      " [18.27444  ]\n",
      " [25.975483 ]\n",
      " [21.157238 ]\n",
      " [24.042767 ]\n",
      " [10.64103  ]\n",
      " [16.268652 ]\n",
      " [23.016232 ]\n",
      " [29.312956 ]\n",
      " [30.892208 ]\n",
      " [15.774073 ]\n",
      " [39.565594 ]\n",
      " [15.405742 ]\n",
      " [21.201286 ]\n",
      " [25.779558 ]\n",
      " [17.738995 ]\n",
      " [26.138126 ]\n",
      " [ 7.2163606]\n",
      " [17.34725  ]\n",
      " [23.437786 ]\n",
      " [21.40339  ]\n",
      " [25.718664 ]\n",
      " [32.60822  ]\n",
      " [13.782552 ]\n",
      " [44.73297  ]\n",
      " [12.073449 ]\n",
      " [23.928535 ]\n",
      " [18.35372  ]\n",
      " [19.825167 ]\n",
      " [15.194916 ]\n",
      " [16.094904 ]\n",
      " [21.721855 ]\n",
      " [31.066397 ]\n",
      " [29.396381 ]\n",
      " [17.863117 ]\n",
      " [17.767078 ]\n",
      " [24.144299 ]\n",
      " [19.290943 ]\n",
      " [23.069656 ]\n",
      " [ 5.853482 ]\n",
      " [24.525711 ]\n",
      " [14.923174 ]\n",
      " [14.268764 ]\n",
      " [17.32749  ]\n",
      " [48.307285 ]\n",
      " [16.702396 ]\n",
      " [12.771842 ]]\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(X_test)\n",
    "print(\"Predicted output\\n\",ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b970eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 878us/step - loss: 11.0136 - mae: 2.2126\n"
     ]
    }
   ],
   "source": [
    "mse,mae = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ec9ab956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 11.013575553894043\n",
      "MAE 2.2126426696777344\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE=\",mse)\n",
    "print(\"MAE\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec2dcb",
   "metadata": {},
   "source": [
    "**PRACTICE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edd7b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c60a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HousingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5acc7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a85b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.611874</td>\n",
       "      <td>11.211934</td>\n",
       "      <td>11.083992</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.518519</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.715432</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.720192</td>\n",
       "      <td>23.388876</td>\n",
       "      <td>6.835896</td>\n",
       "      <td>0.255340</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>27.999513</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.155871</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.175000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.253715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>76.800000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.560263</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>93.975000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  486.000000  486.000000  486.000000  486.000000  506.000000  506.000000   \n",
       "mean     3.611874   11.211934   11.083992    0.069959    0.554695    6.284634   \n",
       "std      8.720192   23.388876    6.835896    0.255340    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081900    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.253715    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.560263   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  486.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.518519    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     27.999513    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.175000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     76.800000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     93.975000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  486.000000  506.000000  \n",
       "mean    12.715432   22.532806  \n",
       "std      7.155871    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      7.125000   17.025000  \n",
       "50%     11.430000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8074564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD          int64\n",
       "TAX          int64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "MEDV       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bd49eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2724576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    df[i] = df[i].fillna(df[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ee6be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f98b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('MEDV',axis =1)\n",
    "Y= df['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dae62397",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "970c8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d507fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = X_train[0].shape, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58c140b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 464.9681 - mae: 20.3469WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 582.1047 - mae: 22.2072 - val_loss: 471.9006 - val_mae: 20.2499\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 511.2584 - mae: 20.6010 - val_loss: 402.7189 - val_mae: 18.5495\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 420.9396 - mae: 18.3367 - val_loss: 310.7847 - val_mae: 16.0124\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 305.6663 - mae: 15.1280 - val_loss: 204.9659 - val_mae: 12.4363\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 181.1711 - mae: 11.0299 - val_loss: 115.6605 - val_mae: 8.5742\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 98.8345 - mae: 7.8884 - val_loss: 74.0035 - val_mae: 6.0730\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 62.5300 - mae: 6.1800 - val_loss: 61.2179 - val_mae: 5.2718\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.5395 - mae: 5.0843 - val_loss: 56.3050 - val_mae: 4.7060\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.3889 - mae: 4.2674 - val_loss: 53.9023 - val_mae: 4.5940\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.1845 - mae: 3.8605 - val_loss: 53.8019 - val_mae: 4.7840\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.2987 - mae: 3.6249 - val_loss: 56.5357 - val_mae: 4.8542\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.3200 - mae: 3.4628 - val_loss: 54.8596 - val_mae: 4.6895\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.9033 - mae: 3.3432 - val_loss: 53.8121 - val_mae: 4.5737\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.8418 - mae: 3.2628 - val_loss: 52.7649 - val_mae: 4.5235\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.8260 - mae: 3.1858 - val_loss: 52.3256 - val_mae: 4.4638\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.1393 - mae: 3.1209 - val_loss: 50.8707 - val_mae: 4.3937\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.3556 - mae: 3.0484 - val_loss: 51.1828 - val_mae: 4.3663\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.7796 - mae: 2.9781 - val_loss: 51.8454 - val_mae: 4.3934\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.1754 - mae: 2.9526 - val_loss: 48.4583 - val_mae: 4.2711\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.6126 - mae: 2.9029 - val_loss: 47.8277 - val_mae: 4.2234\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.1010 - mae: 2.8296 - val_loss: 48.5878 - val_mae: 4.2950\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.7596 - mae: 2.8024 - val_loss: 47.7826 - val_mae: 4.2704\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.3296 - mae: 2.7585 - val_loss: 47.1592 - val_mae: 4.2508\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.0155 - mae: 2.7207 - val_loss: 46.0485 - val_mae: 4.1881\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.6796 - mae: 2.6940 - val_loss: 45.8682 - val_mae: 4.2029\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.3772 - mae: 2.6565 - val_loss: 45.7368 - val_mae: 4.1955\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.1119 - mae: 2.6191 - val_loss: 44.7634 - val_mae: 4.1366\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 12.8521 - mae: 2.6045 - val_loss: 43.5195 - val_mae: 4.0812\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 12.7317 - mae: 2.5901 - val_loss: 43.0416 - val_mae: 4.0683\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 12.4680 - mae: 2.5451 - val_loss: 43.2974 - val_mae: 4.0927\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 12.2041 - mae: 2.5274 - val_loss: 43.2573 - val_mae: 4.0756\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 12.1399 - mae: 2.5170 - val_loss: 41.1151 - val_mae: 3.9450\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 12.0894 - mae: 2.5131 - val_loss: 44.9343 - val_mae: 4.1570\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 11.6892 - mae: 2.4797 - val_loss: 40.6166 - val_mae: 3.9089\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 11.7882 - mae: 2.4641 - val_loss: 40.9264 - val_mae: 3.9685\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 11.6434 - mae: 2.4885 - val_loss: 40.9252 - val_mae: 4.0290\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 11.2760 - mae: 2.4225 - val_loss: 39.5132 - val_mae: 3.9113\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 11.2004 - mae: 2.4005 - val_loss: 39.8798 - val_mae: 3.9310\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 11.2066 - mae: 2.4022 - val_loss: 41.2424 - val_mae: 4.0079\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 10.8865 - mae: 2.3878 - val_loss: 38.7062 - val_mae: 3.8586\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 10.7881 - mae: 2.3638 - val_loss: 39.4943 - val_mae: 3.9039\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 10.6646 - mae: 2.3541 - val_loss: 39.7266 - val_mae: 3.9379\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 10.6467 - mae: 2.3481 - val_loss: 38.3161 - val_mae: 3.8613\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 10.5055 - mae: 2.3425 - val_loss: 41.2537 - val_mae: 4.0538\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 10.3946 - mae: 2.3309 - val_loss: 38.0157 - val_mae: 3.8104\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 10.4065 - mae: 2.3294 - val_loss: 37.4820 - val_mae: 3.8331\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 10.1948 - mae: 2.2967 - val_loss: 38.8911 - val_mae: 3.9211\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.0719 - mae: 2.2791 - val_loss: 38.2149 - val_mae: 3.8790\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.0426 - mae: 2.2830 - val_loss: 37.1961 - val_mae: 3.8027\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.8743 - mae: 2.2675 - val_loss: 38.1061 - val_mae: 3.9087\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.8471 - mae: 2.2523 - val_loss: 38.4781 - val_mae: 3.8949\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.8134 - mae: 2.2690 - val_loss: 37.0345 - val_mae: 3.7964\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.5779 - mae: 2.2334 - val_loss: 37.4267 - val_mae: 3.8465\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.5127 - mae: 2.2173 - val_loss: 36.5049 - val_mae: 3.7885\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.5028 - mae: 2.2387 - val_loss: 36.6546 - val_mae: 3.7868\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.3544 - mae: 2.1960 - val_loss: 36.4507 - val_mae: 3.7992\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.3108 - mae: 2.2115 - val_loss: 36.0209 - val_mae: 3.7624\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.2737 - mae: 2.1920 - val_loss: 35.4693 - val_mae: 3.7160\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.4107 - mae: 2.2087 - val_loss: 35.6271 - val_mae: 3.7825\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 9.1621 - mae: 2.1831 - val_loss: 36.2664 - val_mae: 3.8186\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.9626 - mae: 2.1719 - val_loss: 35.6945 - val_mae: 3.7358\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.8676 - mae: 2.1564 - val_loss: 33.8217 - val_mae: 3.6302\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.9459 - mae: 2.1640 - val_loss: 36.0811 - val_mae: 3.7530\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.8968 - mae: 2.1805 - val_loss: 34.1128 - val_mae: 3.6477\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.8843 - mae: 2.1579 - val_loss: 36.1844 - val_mae: 3.8115\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.5299 - mae: 2.1056 - val_loss: 33.4216 - val_mae: 3.5997\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.5568 - mae: 2.1427 - val_loss: 34.1602 - val_mae: 3.6268\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.5702 - mae: 2.1273 - val_loss: 33.9756 - val_mae: 3.6997\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.4870 - mae: 2.1185 - val_loss: 32.7845 - val_mae: 3.5786\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.3276 - mae: 2.0985 - val_loss: 34.6991 - val_mae: 3.7088\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.2561 - mae: 2.0958 - val_loss: 33.5532 - val_mae: 3.5911\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.1733 - mae: 2.0892 - val_loss: 33.4080 - val_mae: 3.6307\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.1168 - mae: 2.0776 - val_loss: 33.5376 - val_mae: 3.6580\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.1068 - mae: 2.0718 - val_loss: 33.3313 - val_mae: 3.6155\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9883 - mae: 2.0769 - val_loss: 32.5669 - val_mae: 3.5657\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9393 - mae: 2.0547 - val_loss: 33.9046 - val_mae: 3.6420\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8784 - mae: 2.0680 - val_loss: 32.1132 - val_mae: 3.5282\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9045 - mae: 2.0472 - val_loss: 32.8493 - val_mae: 3.5927\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.6608 - mae: 2.0259 - val_loss: 32.3637 - val_mae: 3.5587\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6968 - mae: 2.0455 - val_loss: 30.4259 - val_mae: 3.4832\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.7244 - mae: 2.0182 - val_loss: 32.8953 - val_mae: 3.5674\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.6436 - mae: 2.0502 - val_loss: 31.6110 - val_mae: 3.5253\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.5701 - mae: 2.0105 - val_loss: 32.4262 - val_mae: 3.5636\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.3827 - mae: 2.0022 - val_loss: 30.6663 - val_mae: 3.4526\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.4111 - mae: 1.9969 - val_loss: 31.0033 - val_mae: 3.5038\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.3181 - mae: 1.9976 - val_loss: 31.5284 - val_mae: 3.5108\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.2424 - mae: 1.9854 - val_loss: 30.2197 - val_mae: 3.4352\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.1067 - mae: 1.9666 - val_loss: 31.2379 - val_mae: 3.5058\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.0405 - mae: 1.9557 - val_loss: 30.0854 - val_mae: 3.4332\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.0416 - mae: 1.9517 - val_loss: 30.9294 - val_mae: 3.4985\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.9844 - mae: 1.9426 - val_loss: 30.3622 - val_mae: 3.3971\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.9150 - mae: 1.9439 - val_loss: 30.2580 - val_mae: 3.4247\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.9785 - mae: 1.9563 - val_loss: 30.1447 - val_mae: 3.4640\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.8472 - mae: 1.9216 - val_loss: 30.0501 - val_mae: 3.4003\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.8218 - mae: 1.9474 - val_loss: 30.4097 - val_mae: 3.4623\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7402 - mae: 1.9028 - val_loss: 28.6600 - val_mae: 3.3465\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.6826 - mae: 1.9400 - val_loss: 29.0908 - val_mae: 3.3825\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5832 - mae: 1.8812 - val_loss: 30.1982 - val_mae: 3.4149\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4338 - mae: 1.8790 - val_loss: 28.8808 - val_mae: 3.3470\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.5606 - mae: 1.9237 - val_loss: 29.3744 - val_mae: 3.3510\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, verbose = 1, batch_size =32, epochs =100, validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9f85b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 763us/step - loss: 11.7133 - mae: 2.2204\n",
      "Test MSE, 11.713316917419434\n",
      "\n",
      "Test MAE, 2.2203681468963623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse,mae = model.evaluate(X_test,y_test)\n",
    "print(f\"Test MSE, {mse}\\n\")\n",
    "print(f\"Test MAE, {mae}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66647d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.325748 ],\n",
       "       [34.998463 ],\n",
       "       [15.680397 ],\n",
       "       [26.732677 ],\n",
       "       [14.813835 ],\n",
       "       [20.153418 ],\n",
       "       [16.56278  ],\n",
       "       [15.423666 ],\n",
       "       [24.531511 ],\n",
       "       [17.891487 ],\n",
       "       [20.418766 ],\n",
       "       [16.061453 ],\n",
       "       [ 6.477341 ],\n",
       "       [19.186577 ],\n",
       "       [18.347218 ],\n",
       "       [22.551916 ],\n",
       "       [20.26248  ],\n",
       "       [ 9.160135 ],\n",
       "       [46.361523 ],\n",
       "       [12.549507 ],\n",
       "       [25.624872 ],\n",
       "       [27.60453  ],\n",
       "       [14.901822 ],\n",
       "       [21.794794 ],\n",
       "       [16.520853 ],\n",
       "       [17.473576 ],\n",
       "       [20.157967 ],\n",
       "       [12.301031 ],\n",
       "       [20.405489 ],\n",
       "       [17.418777 ],\n",
       "       [23.515816 ],\n",
       "       [22.927614 ],\n",
       "       [18.359459 ],\n",
       "       [22.543259 ],\n",
       "       [14.673657 ],\n",
       "       [14.1555395],\n",
       "       [31.557682 ],\n",
       "       [20.539577 ],\n",
       "       [21.162174 ],\n",
       "       [25.041767 ],\n",
       "       [16.87468  ],\n",
       "       [29.034054 ],\n",
       "       [49.63689  ],\n",
       "       [18.094376 ],\n",
       "       [26.433777 ],\n",
       "       [15.358822 ],\n",
       "       [15.958805 ],\n",
       "       [27.569233 ],\n",
       "       [19.381382 ],\n",
       "       [25.844917 ],\n",
       "       [17.81659  ],\n",
       "       [33.11159  ],\n",
       "       [16.60363  ],\n",
       "       [24.913774 ],\n",
       "       [43.10523  ],\n",
       "       [22.225506 ],\n",
       "       [14.086245 ],\n",
       "       [33.415577 ],\n",
       "       [25.296303 ],\n",
       "       [14.639532 ],\n",
       "       [25.067877 ],\n",
       "       [35.98139  ],\n",
       "       [29.15912  ],\n",
       "       [16.932926 ],\n",
       "       [23.221462 ],\n",
       "       [19.175188 ],\n",
       "       [15.432959 ],\n",
       "       [23.958366 ],\n",
       "       [29.87323  ],\n",
       "       [12.243565 ],\n",
       "       [22.20709  ],\n",
       "       [26.967663 ],\n",
       "       [ 8.828692 ],\n",
       "       [25.496712 ],\n",
       "       [21.934767 ],\n",
       "       [ 4.4884057],\n",
       "       [21.298286 ],\n",
       "       [47.050926 ],\n",
       "       [11.744066 ],\n",
       "       [11.010617 ],\n",
       "       [20.2118   ],\n",
       "       [12.7287   ],\n",
       "       [21.428219 ],\n",
       "       [10.769779 ],\n",
       "       [20.514484 ],\n",
       "       [26.243414 ],\n",
       "       [16.791122 ],\n",
       "       [23.557432 ],\n",
       "       [27.374832 ],\n",
       "       [18.922466 ],\n",
       "       [23.959995 ],\n",
       "       [ 8.928378 ],\n",
       "       [18.096563 ],\n",
       "       [17.357523 ],\n",
       "       [34.312008 ],\n",
       "       [19.217697 ],\n",
       "       [26.924444 ],\n",
       "       [11.719683 ],\n",
       "       [10.5682125],\n",
       "       [12.930067 ],\n",
       "       [23.11889  ],\n",
       "       [22.169014 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc3f8297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8402739089316178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efe788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
